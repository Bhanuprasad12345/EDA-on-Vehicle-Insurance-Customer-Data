{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7532a96d",
   "metadata": {},
   "source": [
    "# EDA on Vehicle Insurance Customer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f01318c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'customer_details.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6232/1175411017.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# STEP 1: Reading Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtable1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"customer_details.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtable2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"customer_policy_details.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'customer_details.csv'"
     ]
    }
   ],
   "source": [
    "# STEP 1: Reading Data\n",
    "import pandas\n",
    "table1 = pandas.read_csv(\"customer_details.csv\")\n",
    "table2 = pandas.read_csv(\"customer_policy_details.csv\")\n",
    "print(table1.head())\n",
    "print(table2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55fb867c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'table1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6232/3976242514.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# 2.1.1.1 counting the null values of each column of table1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"number of cells of {table1_labels[str(i)]} with null values = {table1[str(i)].isnull().sum()}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'table1' is not defined"
     ]
    }
   ],
   "source": [
    "# STEP 2: Checking and Cleaning the data\n",
    "# 2.1 Null values\n",
    "\n",
    "# 2.1.1 Table1\n",
    "table1_labels={'0':'customer_id', '1':'gender', '2':'age', '3':'driving_licence_presence', \n",
    "'4':'region_code', '5':'previously_insured', '6':'vehicle_age', '7':'vehicle_damage'}\n",
    "\n",
    "# 2.1.1.1 counting the null values of each column of table1\n",
    "for i in range(table1.shape[1]):\n",
    "    print(f\"number of cells of {table1_labels[str(i)]} with null values = {table1[str(i)].isnull().sum()}\")\n",
    "\n",
    "table1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4573defd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.1.2 dropping rows with null customer_id of table1\n",
    "table1.dropna(subset=['0'],inplace=True)\n",
    "print(f\"number of cells of {table1_labels[str(0)]} with null values = {table1[str(0)].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618154e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.1.3 replacing all null values for numeric columns by mean of table1\n",
    "for i in range(2,6):\n",
    "    table1[str(i)].fillna(table1[str(i)].mean(),inplace=True)\n",
    "    print(f\"number of cells of {table1_labels[str(i)]} with null values = {table1[str(i)].isnull().sum()}\")\n",
    "\n",
    "# 2.1.1.4 replacing all null values for Categorical value by mode of table1\n",
    "for i in [1,6,7]:\n",
    "    table1[str(i)].fillna(table1[str(i)].mode()[0],inplace=True)\n",
    "    print(f\"number of cells of {table1_labels[str(i)]} with null values = {table1[str(i)].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2662be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.2 Table2\n",
    "table2_labels={'0':'customer_id', '1':'annual_premium_INR', '2':'sales_channel_code', '3':'vintage', \n",
    "'4':'response'}\n",
    "\n",
    "# 2.1.2.1 counting the null values of each column of table2\n",
    "for i in range(table2.shape[1]):\n",
    "    print(f\"number of cells of {table2_labels[str(i)]} with null values is {table2[str(i)].isnull().sum()}\")\n",
    "\n",
    "table2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de07a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.2.2 dropping rows with null customer_id of table2\n",
    "table2.dropna(subset=['0'],inplace=True)\n",
    "print(f\"number of cells of {table1_labels[str(0)]} with null values = {table2[str(0)].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf905698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.2.3 replacing all null values for numeric columns by mean of table2\n",
    "for i in range(1,5):\n",
    "    table2[str(i)].fillna(table2[str(i)].mean(),inplace=True)\n",
    "    print(f\"number of cells of {table2_labels[str(i)]} with null values = {table2[str(i)].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb425fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Outliers\n",
    "\n",
    "# 2.2.1 Table1\n",
    "\n",
    "table1_limits = {}\n",
    "for i in range(2,6):\n",
    "    computations = table1[str(i)].describe(percentiles=[.25, .75])\n",
    "    mean = computations.values[1]\n",
    "    Q1 = computations.values[4] # 25%\n",
    "    Q3 = computations.values[6] # 75%\n",
    "    IQR = Q3-Q1\n",
    "    ll = Q1 - 1.5*IQR # lower limit\n",
    "    hl = Q3 + 1.5*IQR # higher limit\n",
    "    table1_limits[str(i)] = (ll,hl)\n",
    "table1_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7046081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2.1.1 generating a summary of count of all the outliers column wise of table1 (only for numeric columns)\n",
    "table1_outliers = {'2':0, '3':0, '4':0, '5':0}\n",
    "\n",
    "for j in table1.index:\n",
    "    for i in range(2,6):\n",
    "        if (table1_limits[str(i)][0]!=table1_limits[str(i)][1]) and (table1.loc[j, str(i)]>table1_limits[str(i)][1] or table1.loc[j, str(i)]<table1_limits[str(i)][0]):\n",
    "            table1_outliers[str(i)]+=1\n",
    "\n",
    "table1_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9071adf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2.1.2 replacing all outlier values for numeric columns by mean for table 1\n",
    "# though as can be seen above, there are no outliers at all!, anyways the code is following\n",
    "for j in table1.index:\n",
    "    for i in range(2,6):\n",
    "        if table1.loc[j, str(i)]<table1_limits[str(i)][0]:\n",
    "            table1.loc[j, str(i)]=table1[str(i)].mean()\n",
    "        if table1.loc[j, str(i)]>table1_limits[str(i)][1]:\n",
    "            table1.loc[j, str(i)]=table1[str(i)].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88a4f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2.2 Table2\n",
    "table2_limits = {}\n",
    "\n",
    "for i in range(1,5):\n",
    "    computations = table2[str(i)].describe(percentiles=[.25, .75])\n",
    "    mean = computations.values[1]\n",
    "    Q1 = computations.values[4] # 25%\n",
    "    Q3 = computations.values[6] # 75%\n",
    "    IQR = Q3-Q1\n",
    "    ll = Q1 - 1.5*IQR # lower limit\n",
    "    hl = Q3 + 1.5*IQR # higher limit\n",
    "    table2_limits[str(i)] = (ll,hl)\n",
    "table2_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc86fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2.2.1 generating a summary of count of all the outliers column wise of table2 (only for numeric columns)\n",
    "table2_outliers = {'1':0, '2':0, '3':0, '4':0, '5':0}\n",
    "\n",
    "for j in table2.index:\n",
    "    for i in range(1,5):\n",
    "        if (table2_limits[str(i)][0]!=table2_limits[str(i)][1]) and (table2.loc[j, str(i)]>table2_limits[str(i)][1] or table2.loc[j, str(i)]<table2_limits[str(i)][0]):\n",
    "            table2_outliers[str(i)]+=1\n",
    "\n",
    "table2_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d78e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2.2.2 replacing all outlier values for numeric columns by mean for table 2\n",
    "for j in table2.index:\n",
    "    for i in range(1,5):\n",
    "        if table2.loc[j, str(i)]<table2_limits[str(i)][0]:\n",
    "            table2.loc[j, str(i)]=table2[str(i)].mean()\n",
    "        if table2.loc[j, str(i)]>table2_limits[str(i)][1]:\n",
    "            table2.loc[j, str(i)]=table2[str(i)].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6608100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3.1 Remove Whitespaces for table1\n",
    "table1.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0f1363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3.2 Remove Whitespaces for table2\n",
    "table2.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ee2017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4.1 case correction for table1\n",
    "table1.apply(lambda x: x.str.lower() if x.dtype == \"object\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d4e86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4.2 case correction for table2\n",
    "table2.apply(lambda x: x.str.lower() if x.dtype == \"object\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7dd5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5.1 converting categorical data into dummy variables for table1\n",
    "# 2.5.2 converting categorical data into dummy variables for table2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8feab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.6.1 dropping duplicate rows for table1\n",
    "table1.drop_duplicates(inplace=True)\n",
    "# 2.6.2 dropping duplicate rows for table2\n",
    "table2.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2f6897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP3: Creating a master table\n",
    "data = pandas.merge(table1, table2, on='0',)\n",
    "labels={'0':'customer_id', '1_x':'gender', '2_x':'age', '3_x':'driving_licence_presence', \n",
    "'4_x':'region_code', '5':'previously_insured', '6':'vehicle_age', '7':'vehicle_damage', \n",
    "'1_y':'annual_premium_INR', '2_y':'sales_channel_code', '3_y':'vintage', '4_y':'response'}\n",
    "data.rename(columns=labels, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac050cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP4: getting information\n",
    "# 4.1 Gender wise average annual premium\n",
    "data.groupby('gender')['annual_premium_INR'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d297f422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Age wise average annual premium\n",
    "result4_2 = data.groupby('age')['annual_premium_INR'].mean()\n",
    "import matplotlib.pyplot as pyplot\n",
    "result4_2.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22754767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Is your data balanced between the genders?\n",
    "print(f\"male to female ration is {round(data['gender'].value_counts()[0]/data['gender'].value_counts()[1],2)}\")\n",
    "print(f\"generally, the standard is: \\n balanced data ratio: {50/50}\\n slightly balanced data ratio: {round(55/45,2)}-{60/40} \\n imbalanced data ratio: {80/20}-{90/10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a4c960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4 Vehicle age wise average annual premium.\n",
    "result4_4 = data.groupby('vehicle_age')['annual_premium_INR'].mean()\n",
    "import matplotlib.pyplot as pyplot\n",
    "result4_4.plot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbff068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP5: Is there any relation between Person Age and annual premium?\n",
    "n = data['age'].corr(data['annual_premium_INR'])\n",
    "if n<-0.5:\n",
    "    print(\"Strong negative relationship\")\n",
    "if n>0.5:\n",
    "    print(\"Strong positive relationship\")\n",
    "if n>-0.5 and n<0.5:\n",
    "    print(\"There is no relationship!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9d6ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa44993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a56d62e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
